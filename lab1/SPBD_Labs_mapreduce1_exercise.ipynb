{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-vinha/SPBD/blob/main/lab1/SPBD_Labs_mapreduce1_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Hadoop on Google Colab\n",
        "!curl -s https://raw.githubusercontent.com/smduarte/spbd-2324/main/lab1/install_hadoop.sh | bash"
      ],
      "metadata": {
        "id": "gFHKnDzBHgfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtsPM1Z4HH7M"
      },
      "source": [
        "# Python MapReduce Exercise\n",
        "\n",
        "In the notebook, you should create a map-reduce program that counts the number of occurrences of each word.\n",
        "\n",
        "In this exercise, hadoop runs in standalone mode and reads data from the local filesystem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyRb7RctHH7V"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "7GyGe_WUHH7W"
      },
      "outputs": [],
      "source": [
        "!wget -q -O os_maias.txt https://www.dropbox.com/s/n24v0z7y79np319/os_maias.txt?dl=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN71zF4EHH7X"
      },
      "source": [
        "## WordCount Example\n",
        "Read the words from input and count the number of occurrences of each word.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUdYiNP3HH7X"
      },
      "source": [
        "### Mapper\n",
        "Complete with the code for the mapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08Sc4aHDHH7Y"
      },
      "outputs": [],
      "source": [
        "%%file mapper_words.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# to be completed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9zdUJFHH7Y"
      },
      "source": [
        "### Reducer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xO46HJ9GHH7Z"
      },
      "outputs": [],
      "source": [
        "%%file reducer_words.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# to be completed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzrgMQ6rHH7Z"
      },
      "source": [
        "### Hadoop standalone mode execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80F0mRxaHH7a"
      },
      "source": [
        "\n",
        "The output directory needs to be cleared..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJLOdvJ9HH7a"
      },
      "outputs": [],
      "source": [
        "!rm -rf results_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxyUZV-0HH7b"
      },
      "source": [
        "#### Submitting the job\n",
        "\n",
        "The _hadoop_ command is used to submit the mapreduce job to the cluster..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "gSpFOI3dHH7b"
      },
      "outputs": [],
      "source": [
        "!hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-*streaming*.jar -files mapper_words.py,reducer_words.py -mapper mapper_words.py -reducer reducer_words.py -input os_maias.txt -output results_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8O7AS4cHH7c"
      },
      "source": [
        "#### Checking the results\n",
        "The result is stored in directory results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FL-rCchzHH7c"
      },
      "outputs": [],
      "source": [
        "!cat results_words/part-*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aWhloyjHH7c"
      },
      "source": [
        "## Sorting\n",
        "The results are not sorted. Let's sort them by frequency (the words with higher occurrence first)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g6I-ef9HH7c"
      },
      "source": [
        "### Mapper\n",
        "Complete with the code for the mapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oZIpxznHH7d"
      },
      "outputs": [],
      "source": [
        "%%file mapper_sort.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# to be completed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4shAZHvHH7d"
      },
      "source": [
        "### Reducer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RANPCoO2HH7d"
      },
      "outputs": [],
      "source": [
        "%%file reducer_sort.py\n",
        "#!/usr/bin/env python\n",
        "\n",
        "# to be completed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-4bafTRHH7d"
      },
      "source": [
        "### Hadoop standalone mode execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPt-Kbc9HH7e"
      },
      "source": [
        "\n",
        "The output directory needs to be cleared..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mlobbl3JHH7e"
      },
      "outputs": [],
      "source": [
        "!rm -rf results_sort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDGg3OMXHH7e"
      },
      "source": [
        "#### Submitting the job\n",
        "\n",
        "The _hadoop_ command is used to submit the mapreduce job to the cluster...\n",
        "\n",
        "Note that the results from previous map reduce step are going to be the input for the sorting step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "vSaPukp6HH7e"
      },
      "outputs": [],
      "source": [
        "!hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-*streaming*.jar -files mapper_sort.py,reducer_sort.py -mapper mapper_sort.py -reducer reducer_sort.py -input results_words/part-* -output results_sort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2lk5xGzHH7f"
      },
      "source": [
        "#### Checking the results\n",
        "The result is stored in directory results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qiBDU1acHH7f"
      },
      "outputs": [],
      "source": [
        "!cat results_sort/part-*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}